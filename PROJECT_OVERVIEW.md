# Auto-Annotation Learning Engine - Project Overview

## ğŸ¯ Project Summary

This is a **fully automatic image dataset annotation system** that learns to organize unlabeled images into user-defined classes through iterative prototype refinement. It works for **any dataset size** (from 20 images to millions) and **any domain** (animals, vehicles, textures, etc.).

### Key Innovation
Unlike traditional annotation systems that use hard thresholds or require human review, this engine uses a **self-refining learning loop** that:
- Starts with text embeddings of class names
- Iteratively aligns clusters with class semantics
- Assigns every image using maximum likelihood
- Never rejects or discards data

## ğŸ“ Project Structure

```
learning_loop_T1/
â”‚
â”œâ”€â”€ auto_annotation_engine.py    # Core learning loop implementation
â”‚   â”œâ”€â”€ AutoAnnotationEngine      # Main engine class
â”‚   â”œâ”€â”€ ClusterData               # Data container
â”‚   â”œâ”€â”€ LearningResult            # Results container
â”‚   â””â”€â”€ ImageLevelRefinement      # Fallback for coarse clusters
â”‚
â”œâ”€â”€ data_loader.py                # Data loading and preprocessing
â”‚   â”œâ”€â”€ DataLoader                # Load embeddings and clusters
â”‚   â”œâ”€â”€ TextEmbeddingGenerator    # Generate text embeddings (CLIP, etc.)
â”‚   â””â”€â”€ ClusteringPipeline        # Compute clusters (HDBSCAN, Agglomerative)
â”‚
â”œâ”€â”€ dataset_organizer.py          # Output organization
â”‚   â””â”€â”€ DatasetOrganizer          # Organize into class folders, export splits
â”‚
â”œâ”€â”€ config.py                     # Configuration management
â”‚   â”œâ”€â”€ AutoAnnotationConfig      # Config dataclass
â”‚   â””â”€â”€ Preset configs            # Small/medium/large dataset presets
â”‚
â”œâ”€â”€ main.py                       # Command-line interface
â”œâ”€â”€ example_usage.py              # Complete pipeline examples
â”œâ”€â”€ test_engine.py                # Unit and integration tests
â”œâ”€â”€ visualizer.py                 # Visualization utilities (optional)
â”‚
â”œâ”€â”€ README.md                     # Full documentation
â”œâ”€â”€ QUICKSTART.md                 # Quick start guide
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ .gitignore                    # Git ignore rules
```

## ğŸ”¬ Algorithm Overview

### Phase 1: Initialization
```
For each class name c:
    P_c(0) = TextEmbed(c)  # Initial prototype from text
```

### Phase 2: Learning Loop (3-5 iterations)
```
For iteration t = 1 to T:
    # Step 1: Compute similarities
    s(k,c) = cosine_similarity(Cluster_k, Prototype_c)
    
    # Step 2: Soft assignment
    Î³(k,c) = softmax(s(k,c) / temperature)
    
    # Step 3: Update prototypes
    P_c(t+1) = Î£_k [Î³(k,c) * Cluster_k] / Î£_k Î³(k,c)
    
    # Step 4: Refine at micro-cluster level
    # (same process but with finer clusters)
```

### Phase 3: Label Propagation
```
For each image i:
    label(i) = argmax_c similarity(Image_i, Prototype_c)
    confidence(i) = max_c similarity(Image_i, Prototype_c)
```

## ğŸš€ Usage Patterns

### Pattern 1: Simple CLI Usage
```bash
python main.py --demo                           # Demo mode
python main.py --embeddings E.npy \            # Your data
               --image-paths paths.txt \
               --classes dog cat bird \
               --output results
```

### Pattern 2: Python API
```python
from example_usage import run_complete_pipeline

run_complete_pipeline(
    embeddings_path="embeddings.npy",
    image_paths_file="image_paths.txt",
    class_names=["dog", "cat", "bird"],
    output_dir="results"
)
```

### Pattern 3: Custom Pipeline
```python
from auto_annotation_engine import AutoAnnotationEngine
from data_loader import ClusteringPipeline, TextEmbeddingGenerator

# Your custom logic here
embeddings = load_your_embeddings()
clusters = compute_your_clusters()
text_embeds = generate_text_embeddings()

engine = AutoAnnotationEngine(...)
result = engine.run_learning_loop()
```

## ğŸ“Š Input/Output Specification

### Inputs
1. **Image Embeddings** (required)
   - Format: `.npy` file, shape `[N, D]`
   - Normalized: L2-normalized (unit vectors)
   - Source: CLIP, ResNet, DINOv2, etc.

2. **Image Paths** (required)
   - Format: Text file (one path per line) or JSON
   - Must match embedding order

3. **Class Names** (required)
   - List: `["dog", "cat", "bird"]`

4. **Cluster Data** (optional - computed if not provided)
   - Micro-cluster assignments, centroids
   - Meta-cluster assignments, centroids

### Outputs
```
output_dir/
â”œâ”€â”€ class_folders/          # Images organized by class
â”œâ”€â”€ metadata.json           # Complete annotations + stats
â”œâ”€â”€ report.txt             # Human-readable summary
â”œâ”€â”€ class_prototypes.npy   # Learned prototypes [C, D]
â”œâ”€â”€ *_alignment.npy        # Soft cluster-to-class alignment
â””â”€â”€ splits/                # Train/val/test splits
```

## ğŸ›ï¸ Configuration Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `num_iterations` | 5 | Learning loop iterations (3-7) |
| `temperature` | 0.1 | Softmax temperature (0.05-0.5) |
| `min_cluster_size` | auto | HDBSCAN min cluster size |
| `text_embedding_method` | "clip" | Text embedding method |
| `copy_files` | True | Copy vs symlink images |
| `create_splits` | True | Create train/val/test splits |

### Presets
- **Small dataset** (<100 images): Lower clustering thresholds, more iterations
- **Medium dataset** (100-10K): Balanced settings
- **Large dataset** (>10K): Symlinks, fewer refinements

## ğŸ§ª Testing

### Run Tests
```bash
# Unit tests
pytest test_engine.py -v

# Integration test
python test_engine.py

# Quick validation
python main.py --demo
```

### Test Coverage
- âœ… Engine initialization
- âœ… Learning loop execution
- âœ… Similarity computation
- âœ… Softmax and normalization
- âœ… Clustering pipeline
- âœ… Dataset organization
- âœ… End-to-end integration

## ğŸ“ˆ Performance Characteristics

### Scalability
- **20 images**: ~1 second
- **1,000 images**: ~10 seconds
- **100,000 images**: ~5 minutes
- **1M+ images**: ~1 hour (with optimizations)

### Memory Usage
- Primarily stores: embeddings [N, D] and prototypes [C, D]
- Typical: 1GB for 100K images with D=512

### Accuracy
- Depends on embedding quality and class separability
- Typical confidence scores: 0.6-0.9
- Works best with meaningful embeddings (CLIP, DINOv2)

## ğŸ”§ Customization Points

### 1. Text Embedding Method
```python
# Use CLIP
text_embeddings = TextEmbeddingGenerator.generate_clip_embeddings(classes)

# Use Sentence Transformers
text_embeddings = TextEmbeddingGenerator.generate_sentence_transformer_embeddings(classes)

# Use custom
text_embeddings = your_custom_function(classes)
```

### 2. Clustering Strategy
```python
# Change HDBSCAN parameters
micro_assignments, centroids = ClusteringPipeline.compute_micro_clusters(
    embeddings,
    min_cluster_size=10,  # Customize
    min_samples=5         # Customize
)

# Use different clustering algorithm
# Implement your own in ClusteringPipeline
```

### 3. Learning Loop
```python
# Adjust learning parameters
engine = AutoAnnotationEngine(
    ...,
    num_iterations=7,      # More refinement
    temperature=0.05,      # Sharper assignments
    verbose=True
)
```

### 4. Output Format
```python
organizer.export_for_training(
    format="classification",  # or "yolo", "coco"
    split_ratios={'train': 0.7, 'val': 0.15, 'test': 0.15}
)
```

## ğŸ¨ Visualization (Optional)

```bash
# Install visualization dependencies
pip install matplotlib seaborn

# Generate visualizations
python visualizer.py output_directory

# Outputs:
#   - class_distribution.png
#   - confidence_distribution.png
#   - learning_convergence.png
#   - cluster_alignment.png
#   - confidence_by_class.png
```

## ğŸ”„ Integration with ML Pipelines

### Use Case 1: Bootstrap Training Data
```python
# 1. Auto-annotate
run_complete_pipeline(...)

# 2. Train classifier
from torchvision.datasets import ImageFolder
dataset = ImageFolder('output/splits/train')
# ... train model
```

### Use Case 2: Active Learning Loop
```python
# 1. Auto-annotate
result = engine.run_learning_loop()

# 2. Identify low-confidence samples
low_conf_indices = np.where(result.confidence_scores < 0.5)[0]

# 3. Request manual labels for these
# 4. Re-train embeddings
# 5. Repeat
```

### Use Case 3: Dataset Exploration
```python
# Use to understand dataset structure
result = engine.run_learning_loop()

# Analyze cluster alignments
print(result.meta_cluster_alignment)
# Shows which clusters map to which classes
```

## ğŸ›¡ï¸ Design Principles

### âœ… What This Does
- Automatic label assignment for ALL images
- Maximum-likelihood decisions
- Self-refining prototypes
- Works with any cluster/class ratio
- Handles imbalanced data
- Domain-agnostic

### âŒ What This Doesn't Do
- Use hard thresholds
- Create "unknown" class
- Require human review
- Assume clusters = classes
- Discard low-confidence data
- Need balanced distributions

## ğŸ“ Citation

```bibtex
@software{auto_annotation_engine_2026,
  title={Auto-Annotation Learning Engine},
  author={Your Name},
  year={2026},
  url={https://github.com/your-repo/learning_loop_T1}
}
```

## ğŸ¤ Contributing

Contributions welcome! Priority areas:
1. Additional export formats (YOLO, COCO)
2. Streaming/online learning mode
3. Multi-modal embeddings
4. Distributed processing for massive datasets

## ğŸ“„ License

MIT License - Free for commercial and research use.

## ğŸ†˜ Support

- Issues: GitHub Issues
- Questions: Discussion board
- Email: your-email@example.com

---

**Built for the ML community. Made with â¤ï¸**

Last updated: January 2026
Version: 1.0.0
